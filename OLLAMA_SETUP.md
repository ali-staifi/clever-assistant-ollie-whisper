# Configuration Automatique Ollama CORS

Ce projet inclut une configuration automatique pour Ollama permettant d'√©viter les erreurs CORS lors de l'utilisation de l'API depuis une application web.

## üöÄ Configuration Rapide

### Option 1: Via l'Interface Utilisateur
1. Ouvrez l'application et allez dans les **Param√®tres**
2. Dans la section **Configuration Automatique Ollama**, cliquez sur **Auto-Config**
3. Suivez les instructions affich√©es selon votre syst√®me d'exploitation

### Option 2: Via Scripts NPM (Recommand√©)

Ajoutez ces scripts √† votre `package.json`:

```json
{
  "scripts": {
    "setup-ollama": "node scripts/setup-ollama.js",
    "dev:full": "npm run setup-ollama & npm run dev",
    "ollama:start": "node scripts/setup-ollama.js",
    "ollama:stop": "pkill -f ollama || taskkill /F /IM ollama.exe"
  }
}
```

Puis ex√©cutez:
```bash
npm run setup-ollama
```

### Option 3: Configuration Manuelle

#### Windows (PowerShell)
```powershell
$env:OLLAMA_ORIGINS="*"
$env:OLLAMA_HOST="0.0.0.0:11434"
ollama serve
```

#### Windows (CMD)
```cmd
set OLLAMA_ORIGINS=*
set OLLAMA_HOST=0.0.0.0:11434
ollama serve
```

#### macOS/Linux
```bash
export OLLAMA_ORIGINS="*"
export OLLAMA_HOST="0.0.0.0:11434"
ollama serve
```

## üîß Variables d'Environnement

| Variable | Valeur | Description |
|----------|--------|-------------|
| `OLLAMA_ORIGINS` | `"*"` | Autorise toutes les origines CORS |
| `OLLAMA_HOST` | `"0.0.0.0:11434"` | √âcoute sur toutes les interfaces r√©seau |

## üìã V√©rification de la Configuration

L'interface utilisateur affiche en temps r√©el:
- ‚úÖ **Serveur**: √âtat du serveur Ollama
- ‚úÖ **CORS**: Configuration CORS active
- ‚úÖ **Host**: Configuration d'√©coute r√©seau

## üêõ D√©pannage

### Erreur "Connection refused"
```bash
# V√©rifier si Ollama est install√©
ollama --version

# Installer Ollama si n√©cessaire
# Windows: T√©l√©charger depuis https://ollama.ai/
# macOS: brew install ollama
# Linux: curl -fsSL https://ollama.ai/install.sh | sh
```

### Erreur CORS
```bash
# V√©rifier les variables d'environnement
echo $OLLAMA_ORIGINS  # doit afficher "*"
echo $OLLAMA_HOST     # doit afficher "0.0.0.0:11434"
```

### Port d√©j√† utilis√©
```bash
# Arr√™ter les processus Ollama existants
# Windows
taskkill /F /IM ollama.exe

# macOS/Linux
pkill -f ollama
```

## üìÅ Structure des Fichiers

```
scripts/
‚îú‚îÄ‚îÄ setup-ollama.js           # Script de configuration automatique
src/
‚îú‚îÄ‚îÄ services/ollama/
‚îÇ   ‚îî‚îÄ‚îÄ OllamaConfigService.ts # Service de configuration
‚îî‚îÄ‚îÄ components/settings/
    ‚îî‚îÄ‚îÄ OllamaAutoConfig.tsx   # Interface de configuration
```

## üîç Test de la Configuration

Vous pouvez tester manuellement la configuration:

```bash
# Test de base
curl http://localhost:11434/api/tags

# Test CORS
curl -H "Origin: http://localhost:8080" \
     -H "Access-Control-Request-Method: GET" \
     -X OPTIONS \
     http://localhost:11434/api/tags
```

## üìö Ressources

- [Documentation officielle Ollama](https://github.com/ollama/ollama)
- [Guide des variables d'environnement](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-do-i-configure-ollama-server)
- [LocalSite-ai - Inspiration pour cette impl√©mentation](https://github.com/weise25/LocalSite-ai)

## ü§ù Contribution

Cette impl√©mentation s'inspire du projet [LocalSite-ai](https://github.com/weise25/LocalSite-ai.git) pour la configuration automatique CORS d'Ollama.